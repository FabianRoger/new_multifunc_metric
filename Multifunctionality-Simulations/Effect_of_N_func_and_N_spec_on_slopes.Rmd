---
title: "Effect of varying number of functions and species on the slope of the multithreshold and the averaging approach "
output:
  html_document: default
---

This script produces:

+ Figure 2 b & c

(see `Effect on averaging approach` below for Figure 2 a)

This script sets up the simulations to show the effect of including a varying number of functions and (separately) a varying number of species on the slope pattern produced by the multithreshold approach. 

For the **variable number of function simulation** we hold species richness constant at `specnum`. 

We then define a set number of functions of size `funcnum` from which we draw all possible (but max 50) subsets of variable size (3 subsets-sizes total). For each subset of functions we calculate the multithreshold approach. 

For the **variable number of species simulation** we hold the number of functions constant at `funcnum` but calculate the multithreshold approach for the full species range and two smaller subsets.  


```{r, echo = FALSE, warning=FALSE, message=FALSE, "load packages"}

library(dplyr)
library(tidyr)
library(ggplot2)
library(cowplot)

source("Multifunc_simulations_functions.R")
```

# Effect on multithreshold approach

## Variable number of function simulation

### Simulate full diversity experiment

One can set the same parameters as in most other simulations:

+ `distribution` : the distribution function. The names of the parameters must be changed accordingly in `FunctionValue()`
+ `specnum` : the (maximum) number of species
+ `funcnum` : the (maximum) number of functions 
+ `method` : the method to use (with or without complementarity)

Additional parameters for `method = comp`:

+ `CF` : maximum complementarity factor 
+ `compfunc` : which functions should experience complementarity (`all` or any combination of `func.names`)
+ `r` : the *growthrate* of the complementarity factor

Here we use a maximum replication of 200 unique species combinations as otherwise the computation becomes tedious.
```{r}
set.seed(777)

specnum <- 12
funcnum <- 9

distribution = "runif"

FuncMat <- FunctionValue(specnum,funcnum, distribution, min = 0, max = 1)

func.names <- as.character( unique( FuncMat$Functions))
spec.names <- as.character( unique( FuncMat$Species))

#maxrep <- choose(specnum, floor(specnum/2))
maxrep <- 200 #using the full replications is prohibitive

SpecMat <- SpeciesMatrix(specnum = specnum, maxrep = maxrep)

method = "av"

AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method, 
                          CF = CF, 
                          compfunc = compfunc,
                          r = r)

# standardize functions
AvFunc_func <- AvFunc %>% 
  mutate_at(vars(one_of(func.names)), function(x) {(x) / max(x)})
  #mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})
```

### Variable number of function simulation
```{r}
# empty dataframe to store results
RES_func <- data.frame(thresholds = numeric(), 
                   Estimate = numeric(), 
                   nfunc = numeric(),
                   func_comb = numeric())

#loop over chosen subsets of all function of varying size
for (i in c(ceiling(funcnum/3), 2*ceiling(funcnum/3), funcnum)) { 

  # all poosibel combination of i out of funcnum functions
  func_comb <- combn(func.names, i)
  
  # sample 50 random function combinations if more than 50 possible combinations
  if(ncol(func_comb) > 50) {
    func_comb <- func_comb[, sample(c(1:ncol(func_comb)), 50)]
  }

  #loop over all function combinations of size i
  for ( k  in seq_len(ncol(func_comb))) {
    
######
    
#now evenness
#AvFunc[["Functional Evenness"]] <- AvFunc %>% funcEven(func.names)

#Now our multifunctionality metric - I could have
#done this as a product, but I'm guessing people will want a function
#AvFunc$Multifunctionality <- AvFunc %>% getMF(func.names)

#AvFunc[["effectiveFunctions"]] <- AvFunc[,func.names] %>% multifunc::eff_div(q = 1)
#AvFunc <- mutate(AvFunc, newMF_effN = effectiveFunctions * meanFunction)

#####   

    # number of functions above threshold
    mixedThresh <- getFuncsMaxed(AvFunc, func_comb[ ,k], threshmin=0.05,
                                 threshmax=0.99, prepend=c("Richness"), maxN=1)
    # slopes  
    mixedLinearSlopes<-getCoefTab(funcMaxed ~ Richness, fun = lm, 
                                  data=mixedThresh, coefVar="Richness")
    
    colnames(mixedLinearSlopes) <- c("thresholds", "Estimate",
                                     "Std. Error", "t value", "Pr(>|t|)")
    
    temp <- mixedLinearSlopes %>% 
      select(thresholds, Estimate) %>% 
      mutate(nfunc = i) %>% 
      mutate(func_comb = k)
    
    RES_func <- rbind(RES_func, temp)
  }
  }

```

### Plot with variable number of functions

```{r, fig.height = 4, fig.width = 4}

FUNC <- RES_func %>% 
  group_by(thresholds, nfunc) %>% 
  summarise(mean_Estimate = mean(Estimate),
            CI_high = mean(Estimate) + 1.96 * (sd(Estimate)/sqrt(n())),
            CI_low = mean(Estimate) - 1.96 * (sd(Estimate)/sqrt(n()))) %>% 
ggplot(., aes(x=thresholds*100, y=mean_Estimate), size = 0.5, alpha = 0.3)+
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = as.factor(nfunc)), colour = NA, alpha = 0.4)+
  geom_line( aes(colour = as.factor(nfunc)), lwd = 0.8) +
  ylab("Slope estimate") + xlab("Threshold (%)") +
  geom_abline(intercept=0, slope=0, lwd=0.5, linetype=2) + 
  theme_bw(base_size=15)+
  scale_fill_brewer(guide = FALSE, palette = "Set1")+
  scale_color_brewer(guide = guide_legend(title = paste("Number of functions", 
                                                        paste("(", specnum, " species)", 
                                                              sep = ""), sep = "\n"),
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  theme_classic()+
  theme(legend.position = "bottom")+
  scale_y_continuous(limits = c(-0.45, 0.45)) 
  
FUNC
```

## Variable number of species simulation

### Simulate full diversity experiment

Here we use the full replication

```{r}
set.seed(777)

specnum <- 15
funcnum <- 9

distribution = "runif"

FuncMat <- FunctionValue(specnum,funcnum, distribution, min = 0, max = 1)

func.names <- as.character( unique( FuncMat$Functions))
spec.names <- as.character( unique( FuncMat$Species))

maxrep <- choose(specnum, floor(specnum/2))
#maxrep <- 200 #using the full replications is prohibitive

SpecMat <- SpeciesMatrix(specnum = specnum, maxrep = maxrep)

method = "av"

AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method, 
                          CF = CF, 
                          compfunc = compfunc,
                          r = r)

# standardize functions
AvFunc_func <- AvFunc %>% 
   mutate_at(vars(one_of(func.names)), function(x) {(x / max(x))})
 # mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})
```

### Variable number of species simulation
```{r}

# empty dataframe to store results
RES_spec <- data.frame(thresholds = numeric(), 
                   Estimate = numeric(),
                   `Std. Error` = numeric(), 
                   nspec = numeric())

#loop over three subsets of specnum
for (i in c(6, 9, specnum)) { 

  #subset for number of species to include
  AvFunc_spec <- filter(AvFunc, Richness %in% 1:i) 
  
  # number of functions above threshold
  mixedThresh <- getFuncsMaxed(AvFunc_spec, func.names,
                               threshmin=0.05, threshmax=0.99,
                               prepend=c("Richness"), maxN=1)

  #slopes
  mixedLinearSlopes<-getCoefTab(funcMaxed ~ Richness, fun = lm,
                                data=mixedThresh, coefVar="Richness")
    
  
  temp <- mixedLinearSlopes %>% 
      select(thresholds, Estimate, `Std. Error`) %>% 
      mutate(nspec = i)
    
    RES_spec <- rbind(RES_spec, temp)
  }

```

### Plot with variable number of species

```{r, fig.height = 4, fig.width = 4}
#plot
SPEC <- RES_spec %>% 
  group_by(thresholds, nspec) %>% 
  mutate(CI_high = Estimate + 1.96 * `Std. Error`,
            CI_low = Estimate - 1.96 * `Std. Error`) %>% 
ggplot(., aes(x=thresholds*100, y=Estimate), size = 0.5, alpha = 0.3)+
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = as.factor(nspec)), colour = NA, alpha = 0.4)+
  geom_line( aes(colour = as.factor(nspec)), lwd = 0.8) +
  ylab("Slope estimate") + xlab("Threshold (%)") +
  geom_abline(intercept=0, slope=0, lwd=0.5, linetype=2) + 
  theme_bw(base_size=15)+
  scale_fill_brewer(guide = FALSE, palette = "Set1")+
  scale_color_brewer(guide = guide_legend(title = paste("Number of species", 
                                                        paste("(", funcnum, " functions)", 
                                                              sep = ""), sep = "\n"),
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  theme_classic()+
  theme(legend.position = "bottom")+
  scale_y_continuous(limits = c(-0.45, 0.45)) 
  
SPEC
```



# Effect on averaging approach

This script sets up the simulations to show the effect of including a different number of functions (from a set of `funcnum` functions) on the slope of the $average multifunctionality \sim diveristy$ relationship. We simulate all scenarios with 0 : `funcnum` functions subjected to complementary.

From the predefined set of functions we draw all possible sub-sets of function combinations of size 1 : `funcnum`. For each subset we calculate the $average multifunctionailty \sim diversity$ slope. 

**Choosing the pre-set values produces Figure 2a** which shows the relationship of the slope with number of functions. Figure 2 includes scenarios with 0 , 3, 6 and 9 (all) functions subjected to complementary. 

You can set the same parameters as in most other simulations:

+ `distribution` : the distribution function. The names of the parameters must be changed accordingly in `FunctionValue()`
+ `specnum` : the number of species
+ `funcnum` : the number of functions 

`method` is chosen automatically during the simulation

Additional parameters for `method = comp`:

+ `CF` : maximum complementary factor 
+ `r` : the 'growth-rate' of the complementary factor

`compfunc` is set automatically during the simulation

```{r, "function values"}
specnum <- 12
funcnum <- 9

distribution = "runif"

maxrep <- choose(specnum, floor(specnum/2))
#maxrep <- 500

FuncMat <- FunctionValue(specnum,funcnum, distribution, min = 0, max = 1)

func.names <- as.character( unique( FuncMat$Functions))

SpecMat <- SpeciesMatrix(specnum = specnum, maxrep = maxrep)

CF = 3
r = 0.25
```

### simulation of all possible slopes for 1:`funcnum` functions

```{r, "simulation"}

# empty dataframe to store results
Slope_res <- data.frame(Estimate = numeric(),
                        `Std. Error` = numeric(),
                        `t value` = numeric(),    
                        `Pr(>|t|)` = numeric(),
                        nfunc = numeric(),
                        ncomp = numeric())

# loop over all possible number of functions with complementarity
for (l in 0:funcnum) {
  
set.seed(999)

# choose method = average if no functions with complementarity and method = comp otherwise
  if(l == 0) {
    method = "av"
  }  else {
    method = "comp"
    compfunc = func.names[1:l]
  }

# draw function values and calculate mean function for all richness levels
AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method, 
                          CF = CF, 
                          compfunc = compfunc,
                          r = r)

# standardize functions
AvFunc <- AvFunc %>% 
  select(Richness, one_of(func.names)) %>% 
  mutate_at(vars(one_of(func.names)), function(x) {x / max(x)})
  #mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})


# loop over all subsets of function of size 1:funcnum
for (i in seq_len(funcnum)) { 

  # all poosibel combination of i out of funcnum functions
  func_comb <- combn(func.names, i)
  
  # loop over all function combinations of size i
  for ( k  in seq_len(ncol(func_comb))) { 
  
    # calculate mean function
    AvFunc_temp <- AvFunc %>%
      select(Richness, one_of(func_comb[ ,k])) %>% 
      mutate(meanFunction = rowMeans(.[func_comb[ ,k]]))
  
    # fit linear model
    mod <- lm(meanFunction ~ Richness, data = AvFunc_temp)
  
    # get slope estimate
    est <- summary(mod)$coefficients[2,]
    
    # store results
    Slope_res <- data.frame(t(est)) %>% 
      mutate(., nfunc = i) %>% 
      mutate(ncomp = l) %>% 
      rbind(Slope_res, .)
  }
}
}


```

### Plot 
```{r, warnings = F, "plot figure", fig.height= 4, fig.width= 4}
plot_av <- Slope_res %>% 
  filter(ncomp %in% c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) %>% 
  ggplot(aes(x = nfunc, y = Estimate, colour = as.factor(ncomp)))+
  geom_point(position = position_jitterdodge(jitter.width = 0.2, jitter.height = 0, dodge.width = 0.75),
             alpha = 0.5, shape = 21)+
  geom_smooth(method = "lm", se = F, size = 0.5, 
              position = position_dodge(width = 0.5))+
  scale_color_brewer(guide = guide_legend(title = "Number of functions\nwith complementarity",
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  scale_x_continuous(breaks = seq(1,funcnum,1))+
  scale_y_continuous(limits = c(NA, 0.038))+
  labs(y = "Slope estimate",
       x = "Number of functions considered")+
  theme_classic()+
  theme(legend.position = "bottom")
  
 plot_av 

```




### Arrange plots
```{r, fig.width = 10, fig.height=4}
# arrange plots and save
plot <- plot_grid(plot_av, FUNC, SPEC, nrow = 1,
                      labels = c("a", "b", "c"),
                      hjust = -7,
                      vjust = 3,
                      label_size = 15)

plot
ggsave("Figure_2.pdf", plot, height = 4, width = 10)

```

